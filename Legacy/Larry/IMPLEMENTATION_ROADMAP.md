# ğŸ›£ï¸ **í”„ë¡œì íŠ¸ ì œì•ˆì„œ ëŒ€ë¹„ êµ¬í˜„ ë¡œë“œë§µ**

## ğŸ“Š **í˜„ì¬ ìƒíƒœ ë¶„ì„**

### âœ… **ì™„ì„±ëœ ê²ƒë“¤**

1. **ì›¹ ê²Œì„ ì¸í”„ë¼** (ë˜ë¦¬)

   - Flask + SocketIO ì‹¤ì‹œê°„ ê²Œì„
   - GCP Cloud Run ë°°í¬
   - ë¦¬ë”ë³´ë“œ ì‹œìŠ¤í…œ

2. **ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ (ë¶€ë¶„)** (ë˜ë¦¬)

   - State-Action-Reward ë¡œê¹… âœ…
   - Bounding Box ìë™ ìƒì„± âœ…
   - ì„¸ì…˜ ë©”íƒ€ë°ì´í„° ì €ì¥ âœ…

3. **ì¸í”„ë¼ ë„êµ¬** (ë˜ë¦¬)
   - ë°ì´í„° ì¦ê°• ì½”ë“œ (`src/data/augmentation.py`) âœ…
   - ONNX ìµœì í™” ì½”ë“œ (`src/deployment/onnx_optimizer.py`) âœ…
   - ì‹œê°í™” ë„êµ¬ (`src/utils/visualization.py`) âœ…

---

## âŒ **ì œì•ˆì„œ ëŒ€ë¹„ ë¶€ì¡±í•œ ë¶€ë¶„**

### ğŸ”´ **Critical - í”„ë¡œì íŠ¸ ì‹¤íŒ¨ ê°€ëŠ¥ì„±**

| í•­ëª©                    | ì œì•ˆì„œ ìš”êµ¬ì‚¬í•­                | í˜„ì¬ ìƒíƒœ | ê°­                        | ë‹´ë‹¹ì |
| ----------------------- | ------------------------------ | --------- | ------------------------- | ------ |
| **RGB í”„ë ˆì„**          | "purely from raw visual input" | âŒ ì—†ìŒ   | **ì´ë¯¸ì§€ ì €ì¥ êµ¬í˜„ í•„ìš”** | ë˜ë¦¬   |
| **YOLO í›ˆë ¨**           | â‰¥70% mAP                       | âŒ ë¯¸ì‹œì‘ | ëª¨ë¸ í›ˆë ¨ í•„ìš”            | ì œì´   |
| **Policy Distillation** | â‰¥75% action agreement          | âŒ ë¯¸ì‹œì‘ | MLP ì •ì±… í›ˆë ¨ í•„ìš”        | ì œì´   |
| **RL í›ˆë ¨**             | â‰¥20% ì„±ëŠ¥ í–¥ìƒ                 | âŒ ë¯¸ì‹œì‘ | PPO/DQN í›ˆë ¨ í•„ìš”         | í´ë¡œ   |

---

## ğŸ¯ **ì¦‰ì‹œ í•´ê²° í•„ìš” - Phase 1 (ë˜ë¦¬)**

### **1. RGB í”„ë ˆì„ ìº¡ì²˜ êµ¬í˜„** â­â­â­

#### **ëª©í‘œ**

```
collected_gameplay/session_*/
â”œâ”€â”€ frames/              # â† ì´ê²ƒ ì¶”ê°€!
â”‚   â”œâ”€â”€ frame_0000.png
â”‚   â”œâ”€â”€ frame_0001.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ states_actions.jsonl
â””â”€â”€ bboxes.jsonl
```

#### **êµ¬í˜„ ë°©ë²•**

##### **A. í´ë¼ì´ì–¸íŠ¸ (JavaScript) - Canvas ìº¡ì²˜**

```javascript
// index.htmlì— ì¶”ê°€
class GameClient {
  constructor() {
    this.frameBuffer = []; // í”„ë ˆì„ ë²„í¼
    this.captureInterval = 2; // 2í”„ë ˆì„ë§ˆë‹¤ ìº¡ì²˜ (ìš©ëŸ‰ ì ˆì•½)
  }

  captureFrame() {
    // Canvasë¥¼ Base64ë¡œ ì¸ì½”ë”©
    const frameData = this.canvas.toDataURL("image/png");

    // ì„œë²„ë¡œ ì „ì†¡ (ë²„í¼ë§)
    this.frameBuffer.push({
      frame: this.gameState.frame,
      data: frameData.split(",")[1], // Base64ë§Œ ì¶”ì¶œ
    });

    // 10í”„ë ˆì„ë§ˆë‹¤ ì¼ê´„ ì „ì†¡
    if (this.frameBuffer.length >= 10) {
      this.socket.emit("save_frames", {
        session_id: this.sessionId,
        frames: this.frameBuffer,
      });
      this.frameBuffer = [];
    }
  }

  render() {
    // ê²Œì„ ë Œë”ë§
    // ...

    // í”„ë ˆì„ ìº¡ì²˜ (ì˜µì…˜)
    if (this.isRecording && this.gameState.frame % this.captureInterval === 0) {
      this.captureFrame();
    }
  }
}
```

##### **B. ì„œë²„ (Python) - í”„ë ˆì„ ì €ì¥**

```python
# app.pyì— ì¶”ê°€
import base64
from PIL import Image
import io

@socketio.on('save_frames')
def handle_save_frames(data):
    """í”„ë ˆì„ ì´ë¯¸ì§€ ì €ì¥"""
    session_id = data['session_id']
    frames = data['frames']

    # ì„¸ì…˜ ë””ë ‰í† ë¦¬ ì°¾ê¸°
    for session_dir in COLLECTED_DIR.glob(f"session_*"):
        metadata_file = session_dir / "metadata.json"
        if metadata_file.exists():
            with open(metadata_file, 'r') as f:
                metadata = json.load(f)
                if metadata['session_id'] == session_id:
                    # frames ë””ë ‰í† ë¦¬ ìƒì„±
                    frames_dir = session_dir / 'frames'
                    frames_dir.mkdir(exist_ok=True)

                    # í”„ë ˆì„ ì €ì¥
                    for frame_data in frames:
                        frame_num = frame_data['frame']
                        base64_data = frame_data['data']

                        # Base64 â†’ PNG
                        image_bytes = base64.b64decode(base64_data)
                        image = Image.open(io.BytesIO(image_bytes))

                        # ì €ì¥
                        frame_file = frames_dir / f"frame_{frame_num:04d}.png"
                        image.save(frame_file, 'PNG')

                    print(f"ğŸ’¾ {len(frames)}ê°œ í”„ë ˆì„ ì €ì¥: {frames_dir.name}")
                    break
```

#### **ì˜ˆìƒ ìš©ëŸ‰**

```
1 í”„ë ˆì„ (960x720 PNG): ~100 KB (ì••ì¶•)
10ì´ˆ ê²Œì„ (300 í”„ë ˆì„, 2í”„ë ˆì„ë§ˆë‹¤ ìº¡ì²˜): 150ì¥ Ã— 100 KB = 15 MB
```

---

### **2. ì „ë¬¸ê°€ ì‹œì—° ë°ì´í„° ìˆ˜ì§‘**

#### **ëª©í‘œ**

- ê³ í’ˆì§ˆ í”Œë ˆì´ 50~100 ì„¸ì…˜
- ê° ì„¸ì…˜ ìƒì¡´ ì‹œê°„ > 60ì´ˆ
- ì´ í”„ë ˆì„ ìˆ˜ > 5,000

#### **ë°©ë²•**

```bash
# ì›¹ ê²Œì„ì—ì„œ Human Modeë¡œ ì—¬ëŸ¬ ë²ˆ í”Œë ˆì´
# ë˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ë¡œ ìë™ í”Œë ˆì´

# í†µê³„ í™•ì¸
curl https://distilled-vision-agent-fhuhwhnu3a-uc.a.run.app/api/stats
```

---

### **3. ë°ì´í„° ì¦ê°• íŒŒì´í”„ë¼ì¸ ì—°ê²°**

#### **í˜„ì¬**

```python
# src/data/augmentation.py - ì½”ë“œëŠ” ìˆìŒ
class BackgroundRandomizer:
    def randomize_background(self, image, new_background):
        # ...
```

#### **í•„ìš”**

```python
# ìˆ˜ì§‘ëœ í”„ë ˆì„ì— ìë™ ì¦ê°• ì ìš©
cd final_project
python scripts/augment_collected_data.py \
    --input web_app/collected_gameplay/ \
    --output data/augmented/ \
    --multiplier 5  # 1ê°œ â†’ 5ê°œë¡œ ì¦ê°•
```

**ê²°ê³¼**:

```
data/augmented/
â”œâ”€â”€ session_20251118_142209_human_aug_0/
â”œâ”€â”€ session_20251118_142209_human_aug_1/
â”œâ”€â”€ session_20251118_142209_human_aug_2/
â””â”€â”€ ...
```

---

## ğŸ”„ **Phase 2 - íŒ€ì› ì‘ì—… (ì œì´ & í´ë¡œ)**

### **ì œì´ (Jeewon) - YOLO í›ˆë ¨**

#### **Input ë°ì´í„°**

```
web_app/collected_gameplay/session_*/
â”œâ”€â”€ frames/frame_*.png      # RGB ì´ë¯¸ì§€ (ë˜ë¦¬ê°€ ì¶”ê°€)
â””â”€â”€ bboxes.jsonl           # ë¼ë²¨ (ì´ë¯¸ ìˆìŒ)
```

#### **ì‘ì—…**

1. **ë°ì´í„° ë³€í™˜** (YOLO í¬ë§·)

   ```python
   # scripts/convert_to_yolo.py (ë˜ë¦¬ê°€ ì œê³µ)
   python scripts/convert_to_yolo.py \
       --input web_app/collected_gameplay/ \
       --output data/labeled/
   ```

2. **YOLOv8 í›ˆë ¨**

   ```python
   # src/models/train_yolo.py (ì œì´ê°€ ì‘ì„±)
   from ultralytics import YOLO

   model = YOLO('yolov8n.pt')
   results = model.train(
       data='data/labeled/dataset.yaml',
       epochs=100,
       imgsz=640,
       batch=16
   )
   ```

3. **ì„±ê³µ ê¸°ì¤€ ë‹¬ì„±**
   - mAP â‰¥ 70% on test set

---

### **í´ë¡œ (Chloe) - RL í›ˆë ¨**

#### **Input ë°ì´í„°**

```
web_app/collected_gameplay/session_*/
â”œâ”€â”€ frames/frame_*.png         # RGB (ë˜ë¦¬ê°€ ì¶”ê°€)
â”œâ”€â”€ states_actions.jsonl      # State-Action-Reward (ì´ë¯¸ ìˆìŒ)
â””â”€â”€ bboxes.jsonl              # ë³´ì¡° ë°ì´í„°
```

#### **ì‘ì—… ì˜µì…˜**

##### **Option 1: Vision-based RL (ì œì•ˆì„œ ì›ë˜ ì˜ë„)**

```python
# src/training/train_ppo_vision.py (í´ë¡œê°€ ì‘ì„±)
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv

# 1. YOLOë¡œ ì´ë¯¸ì§€ â†’ State ë³€í™˜
# 2. PPOë¡œ Policy í•™ìŠµ
model = PPO(
    'CnnPolicy',  # ì´ë¯¸ì§€ ì…ë ¥
    env,
    learning_rate=3e-4,
    n_steps=2048
)
model.learn(total_timesteps=100000)
```

##### **Option 2: State-based RL (í˜„ì¬ ë°ì´í„° í™œìš©)**

```python
# src/training/train_ppo_state.py (í´ë¡œê°€ ì‘ì„±)
from stable_baselines3 import PPO

# states_actions.jsonl ë¡œë“œ â†’ Replay Buffer
# â†’ PPO í›ˆë ¨

model = PPO(
    'MlpPolicy',  # State vector ì…ë ¥
    env,
    learning_rate=3e-4
)
model.learn(total_timesteps=100000)
```

3. **ì„±ê³µ ê¸°ì¤€ ë‹¬ì„±**
   - í‰ê·  ìƒì¡´ ì‹œê°„ â‰¥ 20% í–¥ìƒ

---

## ğŸ“Š **ìµœì¢… ëª©í‘œ - End-to-End Pipeline**

### **ì™„ì„±ëœ ì‹œìŠ¤í…œ**

```
[ì›¹ ê²Œì„]
    â†“ RGB frames
[YOLO Detection] (ì œì´)
    â†“ Bbox + State
[Policy Network] (í´ë¡œ)
    â†“ Action
[ê²Œì„ ì‹¤í–‰]
    â†“ 60 FPS
[ONNX Runtime] (ë˜ë¦¬)
```

### **ì„±ëŠ¥ ê²€ì¦**

```python
# scripts/benchmark.py
results = {
    'detection_mAP': 0.75,      # â‰¥ 0.70 âœ…
    'imitation_accuracy': 0.78, # â‰¥ 0.75 âœ…
    'survival_time_gain': 0.25, # â‰¥ 0.20 âœ…
    'fps': 62                   # â‰¥ 60 âœ…
}
```

---

## ğŸ¯ **íƒ€ì„ë¼ì¸ (ì¶”ì •)**

| Phase | ì‘ì—…                         | ë‹´ë‹¹ | ì˜ˆìƒ ì‹œê°„ |
| ----- | ---------------------------- | ---- | --------- |
| **1** | RGB í”„ë ˆì„ ìº¡ì²˜ êµ¬í˜„         | ë˜ë¦¬ | 3-4ì‹œê°„   |
| **1** | ì „ë¬¸ê°€ ë°ì´í„° ìˆ˜ì§‘ (50 ì„¸ì…˜) | ë˜ë¦¬ | 2-3ì‹œê°„   |
| **1** | ë°ì´í„° ì¦ê°• íŒŒì´í”„ë¼ì¸       | ë˜ë¦¬ | 2ì‹œê°„     |
| **2** | YOLO í›ˆë ¨ & ê²€ì¦             | ì œì´ | 1-2ì¼     |
| **2** | Policy Distillation          | ì œì´ | 1ì¼       |
| **3** | PPO/DQN í›ˆë ¨                 | í´ë¡œ | 1-2ì¼     |
| **4** | ONNX í†µí•© & ìµœì í™”           | ë˜ë¦¬ | 1ì¼       |
| **5** | ìµœì¢… ë²¤ì¹˜ë§ˆí¬ & ë³´ê³ ì„œ       | ì „ì²´ | 1ì¼       |

**ì´ ì˜ˆìƒ ì‹œê°„**: 5-7ì¼

---

## ğŸ“‹ **ì²´í¬ë¦¬ìŠ¤íŠ¸**

### **Phase 1 - ë°ì´í„° ìˆ˜ì§‘ ì™„ì„± (ë˜ë¦¬)**

- [ ] Canvas í”„ë ˆì„ ìº¡ì²˜ êµ¬í˜„
- [ ] ì „ë¬¸ê°€ ì‹œì—° ë°ì´í„° 50+ ì„¸ì…˜
- [ ] ë°ì´í„° ì¦ê°• íŒŒì´í”„ë¼ì¸ ì—°ê²°
- [ ] ë°ì´í„°ì…‹ ê²€ì¦ & í†µê³„

### **Phase 2 - Vision ëª¨ë“ˆ (ì œì´)**

- [ ] YOLO ë°ì´í„°ì…‹ ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸
- [ ] YOLOv8 í›ˆë ¨ (mAP â‰¥ 70%)
- [ ] Policy Distillation êµ¬í˜„ (â‰¥ 75% accuracy)
- [ ] ONNX Export

### **Phase 3 - RL ëª¨ë“ˆ (í´ë¡œ)**

- [ ] PPO/DQN í™˜ê²½ ì„¤ì •
- [ ] ì „ë¬¸ê°€ ë°ì´í„° Replay Buffer ë¡œë“œ
- [ ] Self-Play í›ˆë ¨ (â‰¥ 20% ì„±ëŠ¥ í–¥ìƒ)
- [ ] ONNX Export

### **Phase 4 - í†µí•© & ìµœì í™” (ë˜ë¦¬)**

- [ ] ONNX Runtime í†µí•©
- [ ] 60 FPS ë²¤ì¹˜ë§ˆí¬
- [ ] GCP ë°°í¬
- [ ] ìµœì¢… í…ŒìŠ¤íŠ¸

### **Phase 5 - ë¬¸ì„œí™” & ë³´ê³ ì„œ**

- [ ] ìµœì¢… ë³´ê³ ì„œ ì‘ì„±
- [ ] ë°ëª¨ ë¹„ë””ì˜¤ ì œì‘
- [ ] GitHub README ì—…ë°ì´íŠ¸
- [ ] ì œì¶œ

---

## ğŸš¨ **ë¦¬ìŠ¤í¬ & ëŒ€ì‘ì±…**

| ë¦¬ìŠ¤í¬                    | ëŒ€ì‘ì±…                              |
| ------------------------- | ----------------------------------- |
| **í”„ë ˆì„ ìº¡ì²˜ ìš©ëŸ‰ ì´ˆê³¼** | 2-3 í”„ë ˆì„ë§ˆë‹¤ ìƒ˜í”Œë§, JPEG ì••ì¶•    |
| **YOLO mAP < 70%**        | ë°ì´í„° ì¦ê°• ê°•í™”, ë” í° ëª¨ë¸ ì‹œë„   |
| **RL ìˆ˜ë ´ ì•ˆ ë¨**         | Reward shaping, Curriculum learning |
| **60 FPS ë¯¸ë‹¬**           | ONNX INT8 ì–‘ìí™”, ëª¨ë¸ í¬ê¸° ì¶•ì†Œ    |

---

**ì‘ì„±ì**: ë˜ë¦¬ (Minsuk Kim)  
**ìµœì¢… ìˆ˜ì •**: 2025-11-18  
**ìƒíƒœ**: Phase 1 ì§„í–‰ ì¤‘
